{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import ConcatDataset, Dataset, DataLoader, random_split\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
    "DIRECTORY_PATH = \"/home/mericdemirors/Desktop/TUD_lectures/DLMI/project/project_capsule_dataset\"\n",
    "\n",
    "THRESHOLD = 62859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BleedDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_read_func=\"RGB\"):\n",
    "        self.root_dir = root_dir\n",
    "        self.bleeding_dir = os.path.join(root_dir, \"bleeding\")\n",
    "        self.healthy_dir = os.path.join(root_dir, \"healthy\")\n",
    "\n",
    "        # get image paths\n",
    "        self.x = [os.path.join(self.bleeding_dir, p) for p in os.listdir(self.bleeding_dir)] + [os.path.join(self.healthy_dir, p) for p in os.listdir(self.healthy_dir)]\n",
    "        \n",
    "        # get image labels, bleeding=1, healthy=0\n",
    "        self.y = [1 for _ in os.listdir(self.bleeding_dir)] + [0 for _ in os.listdir(self.healthy_dir)]\n",
    "        self.num_samples = len(os.listdir(self.bleeding_dir)) + len(os.listdir(self.healthy_dir))\n",
    "\n",
    "        # set up the function to use for image reading\n",
    "        # different reading functions can be written and used with this structure\n",
    "        if image_read_func == \"RGB\":\n",
    "            self.image_read_function = self.read_RGB\n",
    "        elif image_read_func == \"gray\":\n",
    "            self.image_read_function = self.read_gray\n",
    "        else:\n",
    "            print(\"Wrong image_read_func parameter\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def read_RGB(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = [0,0,0] # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = [0,0,0] # painting the upper right corner if there is white text parts\n",
    "        image = np.transpose(image, [2,0,1]) # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def read_gray(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = 0 # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = 0 # painting the upper right corner if there is white text parts\n",
    "        image = image[np.newaxis, ...] # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_read_function(idx)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- DATASET SPLIT ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "dataset = BleedDataset(DIRECTORY_PATH, image_read_func=\"RGB\")\n",
    "\n",
    "train_size = int(TRAIN_TEST_SPLIT[0] * len(dataset))\n",
    "test_size = int(TRAIN_TEST_SPLIT[1] * len(dataset))\n",
    "validation_size = len(dataset) - train_size - test_size\n",
    "\n",
    "torch.manual_seed(0) # setting the seed to 0 so dataset split is same for every run\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "train_validation_dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "\n",
    "train_validation_dataloader = DataLoader(train_validation_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Decision Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_tensor_to_RGB_numpy(image):\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def function(image, window_size=18, red_multiplier=5.5, green_multiplier=-9.5, blue_multiplier=-0.5, percentile=2):\n",
    "\n",
    "    image_rgb = image.astype(np.float32)\n",
    "\n",
    "    redness_score = image_rgb[:, :, 0] * red_multiplier + image_rgb[:, :, 1] * green_multiplier + image_rgb[:, :, 2] * blue_multiplier\n",
    "\n",
    "    # remove found spots outside the image\n",
    "    mask = cv2.imread(\"mask_meric.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    redness_score = redness_score - np.abs((mask * np.min(redness_score)))\n",
    "\n",
    "    # Find the top % reddish pixel values\n",
    "    threshold = np.percentile(redness_score, 100-percentile)\n",
    "    high_red_indices = np.where(redness_score >= threshold)\n",
    "\n",
    "    # Initialize variables for the best score and coordinates\n",
    "    max_score = -np.inf\n",
    "    best_coords = (0, 0)\n",
    "\n",
    "    # Calculate window scores only around high redness indices\n",
    "    h, w = redness_score.shape\n",
    "    for row, column in zip(*high_red_indices):\n",
    "        # Define the top-left corner of the window\n",
    "        top_left_row = max(0, row - window_size // 2)\n",
    "        top_left_column = max(0, column - window_size // 2)\n",
    "\n",
    "        # Define the bottom-right corner of the window\n",
    "        bottom_right_row = min(h, top_left_row + window_size)\n",
    "        bottom_right_column = min(w, top_left_column + window_size)\n",
    "\n",
    "        # Extract the window and calculate its redness score\n",
    "        window = redness_score[top_left_row:bottom_right_row, top_left_column:bottom_right_column]\n",
    "        score = np.sum(window)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_coords = (row, column)\n",
    "    \n",
    "    # Highlight the most reddish area on the image\n",
    "    image_rgb = image_rgb.astype(np.uint8)\n",
    "    \n",
    "    left_upper_column_row = [max(0, best_coords[1] - window_size//2), max(0, best_coords[0] - window_size//2)]\n",
    "    right_lower_column_row = [min(w, best_coords[1] + window_size//2), min(h, best_coords[0] + window_size//2)]\n",
    "    cv2.rectangle(image_rgb, left_upper_column_row, right_lower_column_row, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    return max_score, image_rgb\n",
    "\n",
    "decision_function = function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangles bleeding annotation from the dataset bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/mericdemirors/Desktop/TUD_lectures/DLMI/project/project_capsule_dataset/bleeding/image17968.jpg\"\n",
    "df = pd.read_csv(\"/home/mericdemirors/Desktop/TUD_lectures/DLMI/project/project_capsule_dataset/bboxes_bleeding.csv\")\n",
    "\n",
    "image = cv2.imread(path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "line = df[df[\"filename\"] == os.path.split(path)[1]].values[0][1:]\n",
    "xywh = [int(x*576) for x in line]\n",
    "\n",
    "rectangle_image = cv2.rectangle(image, [xywh[0]-xywh[2]//2,xywh[1]-xywh[3]//2], [xywh[0]+xywh[2]//2, xywh[1]+xywh[3]//2], (0, 0, 255), 2)\n",
    "plt.imshow(rectangle_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangles the found most red part (image is read from path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path)\n",
    "image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "image[:48,:48] = [0,0,0] # painting the upper left corner if there is a gray square\n",
    "image[:31, 452:] = [0,0,0] # painting the upper right corner if there is white text parts\n",
    "image = np.transpose(image, [2,0,1]) # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "np_image = torch_tensor_to_RGB_numpy(image)\n",
    "score, annotated_image = decision_function(np_image, *[18, 5.5, -9.5, -0.5, 10])\n",
    "plt.imshow(annotated_image)\n",
    "\n",
    "if score < THRESHOLD:\n",
    "    plt.title(f\"Image redness score: {score}, HEALTHY\")\n",
    "else:\n",
    "    plt.title(f\"Image redness score: {score}, BLEEDING\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image comes from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_dataset[443][0]\n",
    "np_image = torch_tensor_to_RGB_numpy(image)\n",
    "score, annotated_image = decision_function(np_image, *[18, 5.5, -9.5, -0.5, 10])\n",
    "plt.imshow(annotated_image)\n",
    "if score < THRESHOLD:\n",
    "    plt.title(f\"Image redness score: {score}, HEALTHY\")\n",
    "else:\n",
    "    plt.title(f\"Image redness score: {score}, BLEEDING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
