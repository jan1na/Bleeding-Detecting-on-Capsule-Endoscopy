{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Setup"
      ],
      "metadata": {
        "id": "C--R-ap6Hjdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
        "\n",
        "%cd Bleeding-Detecting-on-Capsule-Endoscopy\n",
        "!git checkout \"janina\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')"
      ],
      "metadata": {
        "id": "UxDGWOBxHhDM",
        "outputId": "45423aef-07a1-49c2-bdee-67609be402cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bleeding-Detecting-on-Capsule-Endoscopy'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 112 (delta 66), reused 61 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (112/112), 4.79 MiB | 32.06 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy\n",
            "Branch 'janina' set up to track remote branch 'janina' from 'origin'.\n",
            "Switched to a new branch 'janina'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive Setup"
      ],
      "metadata": {
        "id": "17a-EaHYRx-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (for data storage)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SDTCkZdjR0Wk",
        "outputId": "77a168d7-7770-4df6-b500-8ff13d86041a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNJTrpeGFxF"
      },
      "source": [
        "# Deep Learning Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8R9IP-WGFxH"
      },
      "source": [
        "## TODO\n",
        "* losses should be weighted for different classes, there are 8 to 9 times of healthy images than there is for bleeding, so model will be inclined to predict healthy\n",
        "* hyperparameters for deep learning runs should be saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wr-lhh-GFxI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.897440108Z",
          "start_time": "2025-01-10T15:50:56.799530900Z"
        },
        "id": "hKYYLTpVGFxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56690fa-c8ff-4e84-ecf2-4015e4099596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "\n",
        "from models import MobileNetV2, GoogleNet, ResNet, AlexNet, VGG19\n",
        "from bleeding_dataset import BleedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfnDKDTCGFxJ"
      },
      "source": [
        "## Training Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaqLtj46GFxK"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.919580790Z",
          "start_time": "2025-01-10T15:50:57.913228018Z"
        },
        "id": "Zphq5_ivGFxK"
      },
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
        "\n",
        "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
        "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
        "BATCH_SIZE = 16\n",
        "LR = 0.001 # learning rate\n",
        "\n",
        "NUM_OF_EPOCHS = 20\n",
        "EARLY_STOP_LIMIT = 3\n",
        "\n",
        "THRESHOLD = 0.5 # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction\n",
        "MODEL = MobileNetV2\n",
        "AUGMENT_TIMES = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8keuueGFxL"
      },
      "source": [
        "### Dataset, Model etc. Inıtıalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:58.526936237Z",
          "start_time": "2025-01-10T15:50:57.920838409Z"
        },
        "id": "LkLRM6CyGFxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af3ea1d-d84b-41f0-e815-7d55ca4afa83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 104MB/s] \n",
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts/bleeding_dataset.py:39: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
            "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),  # Distortion\n"
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- MODEL & DATASET ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Model Initialization\n",
        "def initialize_model(model_class, save_path):\n",
        "    model = model_class().to(device)\n",
        "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
        "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
        "    os.makedirs(model_serial_path, exist_ok=True)\n",
        "    return model, model_serial_path\n",
        "\n",
        "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
        "full_dataset = None\n",
        "\n",
        "# Dataset Preparation\n",
        "def prepare_datasets(dataset_class, directory, split_ratios, batch_size, image_mode=\"RGB\", seed=0):\n",
        "    global full_dataset\n",
        "    # if augmentations used: set augment_time=AUGMENT_TIMES\n",
        "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=False, augment_times=1)\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(split_ratios[0] * total_size)\n",
        "    test_size = int(split_ratios[1] * total_size)\n",
        "    validation_size = total_size - train_size - test_size\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "    # Oversampling for bleeding images\n",
        "    train_labels = np.array(full_dataset.get_labels())[train_dataset.indices]\n",
        "    class_counts = np.bincount(train_labels)  # Count occurrences per class\n",
        "    class_weights = 1.0 / class_counts  # Inverse class frequency\n",
        "\n",
        "    weights = [class_weights[label] for label in train_labels]\n",
        "    sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "    return {\n",
        "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
        "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
        "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
        "    }\n",
        "\n",
        "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
        "\n",
        "# Penalty for imbalanced dataset\n",
        "# if augmenations used:\n",
        "# bleeding_weight = 6161 / (713 * AUGMENT_TIMES)\n",
        "bleeding_weight = 6161 / 713\n",
        "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_OF_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbWFmh3zGFxM"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.628953950Z",
          "start_time": "2025-01-10T15:50:58.526428978Z"
        },
        "id": "VSFLnQOzGFxN",
        "outputId": "8beba08b-ac81-4cc5-888b-942eafde7111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1e72e05b72ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maveraged_training_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "train_losses, validation_losses = [], []\n",
        "min_validation_loss = None # minimum achieved loss on validation dataset, used for early stopping\n",
        "min_validation_path = None # path to model checkpoint file\n",
        "early_stop_step = 0\n",
        "\n",
        "\n",
        "for epoch in range(NUM_OF_EPOCHS):\n",
        "\n",
        "    # if use augmentation:\n",
        "    #full_dataset.enable_augmentation()\n",
        "    averaged_training_loss = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        model = model.train()\n",
        "        outputs = model(images.type(torch.float))\n",
        "\n",
        "        float_outputs = outputs[:,0].type(torch.float)\n",
        "        float_labels = labels.type(torch.float)\n",
        "        train_loss = criterion(float_outputs, float_labels)\n",
        "        averaged_training_loss = averaged_training_loss + train_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculating the average loss in this epoch's training loop\n",
        "    averaged_training_loss = averaged_training_loss / len(data_loaders['train'])\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # if use augmentation:\n",
        "        #full_dataset.disable_augmentation()\n",
        "        model = model.eval()\n",
        "\n",
        "        # calculate validation loss\n",
        "        validation_loss = 0.0\n",
        "        for validation_images, validation_labels in data_loaders['validation']:\n",
        "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
        "\n",
        "            validation_outputs = model(validation_images.type(torch.float))\n",
        "\n",
        "            float_validation_outputs = validation_outputs[:,0].type(torch.float)\n",
        "            float_validation_labels = validation_labels.type(torch.float)\n",
        "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
        "\n",
        "\n",
        "        # and average the loss over dataset length\n",
        "        validation_loss /= len(data_loaders['validation'])\n",
        "\n",
        "    # if this is first validation or a new minimum is achieved\n",
        "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
        "        early_stop_step = 0\n",
        "        min_validation_loss = validation_loss\n",
        "\n",
        "        # if there is a checkpoint file, remove it\n",
        "        if min_validation_path is not None:\n",
        "            os.remove(min_validation_path)\n",
        "\n",
        "        # save the new checkpoint file\n",
        "        min_validation_path = os.path.join(model_serial_path, \"min_validation_loss:\"+str(min_validation_loss) + \"_epoch:\" + str(epoch) + \".pth\")\n",
        "        torch.save(model, min_validation_path)\n",
        "    else:\n",
        "        early_stop_step += 1\n",
        "\n",
        "    # log the losses, and append to the lists\n",
        "    print(f\"Epoch: {epoch+1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\", flush=True)\n",
        "    train_losses.append(averaged_training_loss.item())\n",
        "    validation_losses.append(validation_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    # check for early stopping\n",
        "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
        "        print(\"early stopping...\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.628308081Z"
        },
        "id": "eKRtlkFfGFxO"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, color='blue', label='Train Loss')\n",
        "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp8U_4eQGFxO"
      },
      "source": [
        "## Testing Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.630076269Z",
          "start_time": "2025-01-10T15:52:40.629125510Z"
        },
        "id": "POb_wAaHGFxP"
      },
      "outputs": [],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "loaded_model = torch.load(min_validation_path)\n",
        "loaded_model = loaded_model.eval()\n",
        "\n",
        "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
        "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
        "class_correct, class_total = [0,0], [0,0]\n",
        "with torch.no_grad():\n",
        "    # if use augmentation:\n",
        "    #full_dataset.disable_augmentation()\n",
        "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
        "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "\n",
        "        test_outputs = loaded_model(test_images.type(torch.float))\n",
        "\n",
        "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
        "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
        "        test_outputs[test_outputs < THRESHOLD] = 0\n",
        "\n",
        "        # calculate indices for correct predictions\n",
        "        correct = (test_outputs == test_labels).squeeze()\n",
        "        for e, label in enumerate(test_labels):\n",
        "            # increase the correct prediction count for that label\n",
        "            class_correct[label] += correct[e].item()\n",
        "            class_total[label] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.629693529Z"
        },
        "id": "XfY5BWAOGFxP"
      },
      "outputs": [],
      "source": [
        "# Total: accuracy for whole dataset\n",
        "print(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\")\n",
        "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\")\n",
        "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\")\n",
        "\n",
        "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
        "    txt.write(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
        "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\\n\")\n",
        "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\\n\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}