{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Setup"
      ],
      "metadata": {
        "id": "C--R-ap6Hjdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
        "\n",
        "%cd Bleeding-Detecting-on-Capsule-Endoscopy\n",
        "!git checkout \"janina\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')"
      ],
      "metadata": {
        "id": "UxDGWOBxHhDM",
        "outputId": "e893af42-3274-46f7-b09a-37071ed7e251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Bleeding-Detecting-on-Capsule-Endoscopy' already exists and is not an empty directory.\n",
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy\n",
            "Already on 'janina'\n",
            "Your branch is up to date with 'origin/janina'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive Setup"
      ],
      "metadata": {
        "id": "17a-EaHYRx-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (for data storage)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SDTCkZdjR0Wk",
        "outputId": "220274f3-ad1f-440f-84a8-15c62b2b730f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNJTrpeGFxF"
      },
      "source": [
        "# Deep Learning Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8R9IP-WGFxH"
      },
      "source": [
        "## TODO\n",
        "* losses should be weighted for different classes, there are 8 to 9 times of healthy images than there is for bleeding, so model will be inclined to predict healthy\n",
        "* hyperparameters for deep learning runs should be saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wr-lhh-GFxI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.897440108Z",
          "start_time": "2025-01-10T15:50:56.799530900Z"
        },
        "id": "hKYYLTpVGFxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cea3de4-dfab-417c-f4d2-cf4496e9a221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "\n",
        "from models import MobileNetV2, GoogleNet, ResNet, AlexNet, VGG19\n",
        "from bleeding_dataset import BleedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfnDKDTCGFxJ"
      },
      "source": [
        "## Training Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaqLtj46GFxK"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.919580790Z",
          "start_time": "2025-01-10T15:50:57.913228018Z"
        },
        "id": "Zphq5_ivGFxK"
      },
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
        "\n",
        "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
        "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.001 # learning rate\n",
        "\n",
        "NUM_OF_EPOCHS = 20\n",
        "EARLY_STOP_LIMIT = 3\n",
        "\n",
        "THRESHOLD = 0.5 # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction\n",
        "MODEL = MobileNetV2\n",
        "AUGMENT_TIMES = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8keuueGFxL"
      },
      "source": [
        "### Dataset, Model etc. Inıtıalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:58.526936237Z",
          "start_time": "2025-01-10T15:50:57.920838409Z"
        },
        "id": "LkLRM6CyGFxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d5ab78-94e3-4159-b810-08c96875a632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full_dataset: 11865\n",
            "9492\n",
            "9492\n",
            "full_dataset: 11865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts/bleeding_dataset.py:39: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
            "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),  # Distortion\n"
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- MODEL & DATASET ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Model Initialization\n",
        "def initialize_model(model_class, save_path):\n",
        "    model = model_class().to(device)\n",
        "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
        "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
        "    os.makedirs(model_serial_path, exist_ok=True)\n",
        "    return model, model_serial_path\n",
        "\n",
        "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
        "full_dataset = None\n",
        "\n",
        "# Dataset Preparation\n",
        "def prepare_datasets(dataset_class, directory, split_ratios, batch_size, image_mode=\"RGB\", seed=0):\n",
        "    global full_dataset\n",
        "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=True, augment_times=AUGMENT_TIMES)\n",
        "    print(\"full_dataset:\", len(full_dataset))\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(split_ratios[0] * total_size)\n",
        "    test_size = int(split_ratios[1] * total_size)\n",
        "    validation_size = total_size - train_size - test_size\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "    # Apply augmentation **only to the training set**\n",
        "    #validation_dataset.dataset.disable_augmentation()\n",
        "    #test_dataset.dataset.disable_augmentation()\n",
        "\n",
        "    # Oversampling for bleeding images\n",
        "    print(len(train_dataset.indices))\n",
        "    print(train_size)\n",
        "    print(\"full_dataset:\", len(full_dataset))\n",
        "\n",
        "    # Oversampling for bleeding images\n",
        "    train_labels = np.array(full_dataset.get_labels())[train_dataset.indices]\n",
        "    class_counts = np.bincount(train_labels)  # Count occurrences per class\n",
        "    class_weights = 1.0 / class_counts  # Inverse class frequency\n",
        "\n",
        "    weights = [class_weights[label] for label in train_labels]\n",
        "    sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "    return {\n",
        "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
        "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
        "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
        "    }\n",
        "\n",
        "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
        "\n",
        "# Penalty for imbalanced dataset\n",
        "bleeding_weight = 6161 / (713 * AUGMENT_TIMES)\n",
        "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
        "\n",
        "#criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "#scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_OF_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbWFmh3zGFxM"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.628953950Z",
          "start_time": "2025-01-10T15:50:58.526428978Z"
        },
        "id": "VSFLnQOzGFxN",
        "outputId": "572563f9-c007-4c2d-8c3a-57b9d3172774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | training loss: 0.5434083938598633 | min validation loss: 0.6047701945430354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | training loss: 0.5393068194389343 | min validation loss: 0.5516876131296158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | training loss: 0.5314875245094299 | min validation loss: 0.5516876131296158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:18,  2.14it/s]"
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "train_losses, validation_losses = [], []\n",
        "min_validation_loss = None # minimum achieved loss on validation dataset, used for early stopping\n",
        "min_validation_path = None # path to model checkpoint file\n",
        "early_stop_step = 0\n",
        "\n",
        "\n",
        "#from torch.cuda.amp import autocast, GradScaler\n",
        "#scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "for epoch in range(NUM_OF_EPOCHS):\n",
        "    full_dataset.enable_augmentation()\n",
        "    averaged_training_loss = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        model = model.train()\n",
        "        outputs = model(images.type(torch.float))\n",
        "\n",
        "        float_outputs = outputs[:,0].type(torch.float)\n",
        "        float_labels = labels.type(torch.float)\n",
        "        train_loss = criterion(float_outputs, float_labels)\n",
        "        averaged_training_loss = averaged_training_loss + train_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \"\"\"\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(train_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \"\"\"\n",
        "\n",
        "    # calculating the average loss in this epoch's training loop\n",
        "    averaged_training_loss = averaged_training_loss / len(data_loaders['train'])\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        full_dataset.disable_augmentation()\n",
        "        model = model.eval()\n",
        "\n",
        "        # calculate validation loss\n",
        "        validation_loss = 0.0\n",
        "        for validation_images, validation_labels in data_loaders['validation']:\n",
        "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
        "\n",
        "            validation_outputs = model(validation_images.type(torch.float))\n",
        "\n",
        "            float_validation_outputs = validation_outputs[:,0].type(torch.float)\n",
        "            float_validation_labels = validation_labels.type(torch.float)\n",
        "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
        "\n",
        "\n",
        "        # and average the loss over dataset length\n",
        "        validation_loss /= len(data_loaders['validation'])\n",
        "\n",
        "    # if this is first validation or a new minimum is achieved\n",
        "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
        "        early_stop_step = 0\n",
        "        min_validation_loss = validation_loss\n",
        "\n",
        "        # if there is a checkpoint file, remove it\n",
        "        if min_validation_path is not None:\n",
        "            os.remove(min_validation_path)\n",
        "\n",
        "        # save the new checkpoint file\n",
        "        min_validation_path = os.path.join(model_serial_path, \"min_validation_loss:\"+str(min_validation_loss) + \"_epoch:\" + str(epoch) + \".pth\")\n",
        "        torch.save(model, min_validation_path)\n",
        "    else:\n",
        "        early_stop_step += 1\n",
        "\n",
        "    # log the losses, and append to the lists\n",
        "    print(f\"Epoch: {epoch+1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\", flush=True)\n",
        "    train_losses.append(averaged_training_loss.item())\n",
        "    validation_losses.append(validation_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    # check for early stopping\n",
        "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
        "        print(\"early stopping...\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.628308081Z"
        },
        "id": "eKRtlkFfGFxO"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, color='blue', label='Train Loss')\n",
        "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp8U_4eQGFxO"
      },
      "source": [
        "## Testing Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.630076269Z",
          "start_time": "2025-01-10T15:52:40.629125510Z"
        },
        "id": "POb_wAaHGFxP"
      },
      "outputs": [],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "#loaded_model = model.__class__().to(device)\n",
        "loaded_model = torch.load(min_validation_path)\n",
        "loaded_model = loaded_model.eval()\n",
        "\n",
        "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
        "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
        "class_correct, class_total = [0,0], [0,0]\n",
        "with torch.no_grad():\n",
        "    full_dataset.disable_augmentation()\n",
        "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
        "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "\n",
        "        test_outputs = loaded_model(test_images.type(torch.float))\n",
        "\n",
        "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
        "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
        "        test_outputs[test_outputs < THRESHOLD] = 0\n",
        "\n",
        "        # calculate indices for correct predictions\n",
        "        correct = (test_outputs == test_labels).squeeze()\n",
        "        for e, label in enumerate(test_labels):\n",
        "            # increase the correct prediction count for that label\n",
        "            class_correct[label] += correct[e].item()\n",
        "            class_total[label] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.629693529Z"
        },
        "id": "XfY5BWAOGFxP"
      },
      "outputs": [],
      "source": [
        "# Total: accuracy for whole dataset\n",
        "print(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\")\n",
        "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\")\n",
        "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\")\n",
        "\n",
        "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
        "    txt.write(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
        "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\\n\")\n",
        "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\\n\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}