{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Setup"
      ],
      "metadata": {
        "id": "C--R-ap6Hjdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
        "\n",
        "%cd Bleeding-Detecting-on-Capsule-Endoscopy\n",
        "!git checkout \"janina\"\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')"
      ],
      "metadata": {
        "id": "UxDGWOBxHhDM",
        "outputId": "5ac9a097-c1bf-4a83-e7c8-c3e340967b28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bleeding-Detecting-on-Capsule-Endoscopy'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects: 100% (227/227), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 227 (delta 106), reused 144 (delta 41), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (227/227), 12.98 MiB | 17.70 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy\n",
            "Branch 'janina' set up to track remote branch 'janina' from 'origin'.\n",
            "Switched to a new branch 'janina'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive Setup"
      ],
      "metadata": {
        "id": "17a-EaHYRx-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (for data storage)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SDTCkZdjR0Wk",
        "outputId": "f9804d93-649e-4809-b7be-18ab0b0026df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNJTrpeGFxF"
      },
      "source": [
        "# Deep Learning Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8R9IP-WGFxH"
      },
      "source": [
        "## TODO\n",
        "* losses should be weighted for different classes, there are 8 to 9 times of healthy images than there is for bleeding, so model will be inclined to predict healthy\n",
        "* hyperparameters for deep learning runs should be saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wr-lhh-GFxI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.897440108Z",
          "start_time": "2025-01-10T15:50:56.799530900Z"
        },
        "id": "hKYYLTpVGFxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27c4a79-5ab0-40e5-b798-17b4599fc826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "\n",
        "from models import MobileNetV2\n",
        "from bleeding_dataset import BleedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfnDKDTCGFxJ"
      },
      "source": [
        "## Training Space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaqLtj46GFxK"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:57.919580790Z",
          "start_time": "2025-01-10T15:50:57.913228018Z"
        },
        "id": "Zphq5_ivGFxK"
      },
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
        "\n",
        "TRAIN_TEST_SPLIT = (0.8, 0.1)  # remaining parts will be test\n",
        "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
        "BATCH_SIZE = 16\n",
        "LR = 0.001  # learning rate\n",
        "\n",
        "NUM_OF_EPOCHS = 20\n",
        "EARLY_STOP_LIMIT = 3\n",
        "\n",
        "THRESHOLD = 0.5  # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction\n",
        "MODEL = MobileNetV2  # ResNet, AlexNet, VGG19\n",
        "APPLY_AUGMENTATION = False\n",
        "USE_COSINE_ANNEALING_LR = True\n",
        "AUGMENT_TIMES = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8keuueGFxL"
      },
      "source": [
        "### Dataset, Model etc. Inıtıalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:50:58.526936237Z",
          "start_time": "2025-01-10T15:50:57.920838409Z"
        },
        "id": "LkLRM6CyGFxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1702551-2589-4526-e038-0b64f0614407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 214MB/s]\n",
            "/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts/bleeding_dataset.py:35: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
            "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),  # Distortion\n"
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- MODEL & DATASET ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "# Model Initialization\n",
        "def initialize_model(model_class, save_path):\n",
        "    model = model_class().to(device)\n",
        "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
        "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
        "    os.makedirs(model_serial_path, exist_ok=True)\n",
        "    return model, model_serial_path\n",
        "\n",
        "\n",
        "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
        "full_dataset = None\n",
        "\n",
        "\n",
        "# Dataset Preparation\n",
        "def prepare_datasets(dataset_class, directory, split_ratios, batch_size, image_mode=\"RGB\", seed=0):\n",
        "    global full_dataset\n",
        "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=APPLY_AUGMENTATION,\n",
        "                                 augment_times=AUGMENT_TIMES)\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(split_ratios[0] * total_size)\n",
        "    test_size = int(split_ratios[1] * total_size)\n",
        "    validation_size = total_size - train_size - test_size\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset,\n",
        "                                                                   [train_size, validation_size, test_size])\n",
        "\n",
        "    # Oversampling for bleeding images\n",
        "    train_labels = np.array(full_dataset.get_labels())[train_dataset.indices]\n",
        "    class_counts = np.bincount(train_labels)  # Count occurrences per class\n",
        "    class_weights = 1.0 / class_counts  # Inverse class frequency\n",
        "\n",
        "    weights = [class_weights[label] for label in train_labels]\n",
        "    sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "    return {\n",
        "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
        "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4,\n",
        "                                 pin_memory=True),\n",
        "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
        "    }\n",
        "\n",
        "\n",
        "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
        "\n",
        "# Penalty for imbalanced dataset\n",
        "bleeding_weight = 6161 / (713 * AUGMENT_TIMES) if APPLY_AUGMENTATION else 6161 / 713\n",
        "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                           T_max=NUM_OF_EPOCHS) if USE_COSINE_ANNEALING_LR else lr_scheduler.StepLR(\n",
        "    optimizer, step_size=10, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbWFmh3zGFxM"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.628953950Z",
          "start_time": "2025-01-10T15:50:58.526428978Z"
        },
        "id": "VSFLnQOzGFxN",
        "outputId": "2636b5d2-6fc2-42e2-9609-1cdc167d67b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:14,  2.83s/it]"
          ]
        }
      ],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "train_losses, validation_losses = [], []\n",
        "min_validation_loss = None  # minimum achieved loss on validation dataset, used for early stopping\n",
        "min_validation_path = None  # path to model checkpoint file\n",
        "early_stop_step = 0\n",
        "\n",
        "for epoch in range(NUM_OF_EPOCHS):\n",
        "    if APPLY_AUGMENTATION:\n",
        "        full_dataset.enable_augmentation()\n",
        "    averaged_training_loss = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        model = model.train()\n",
        "        outputs = model(images.type(torch.float))\n",
        "\n",
        "        float_outputs = outputs[:, 0].type(torch.float)\n",
        "        float_labels = labels.type(torch.float)\n",
        "        train_loss = criterion(float_outputs, float_labels)\n",
        "        averaged_training_loss = averaged_training_loss + train_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculating the average loss in this epoch's training loop\n",
        "    averaged_training_loss = averaged_training_loss / len(data_loaders['train'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if APPLY_AUGMENTATION:\n",
        "            full_dataset.disable_augmentation()\n",
        "        model = model.eval()\n",
        "\n",
        "        # calculate validation loss\n",
        "        validation_loss = 0.0\n",
        "        for validation_images, validation_labels in data_loaders['validation']:\n",
        "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
        "\n",
        "            validation_outputs = model(validation_images.type(torch.float))\n",
        "\n",
        "            float_validation_outputs = validation_outputs[:, 0].type(torch.float)\n",
        "            float_validation_labels = validation_labels.type(torch.float)\n",
        "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
        "\n",
        "        # and average the loss over dataset length\n",
        "        validation_loss /= len(data_loaders['validation'])\n",
        "\n",
        "    # if this is first validation or a new minimum is achieved\n",
        "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
        "        early_stop_step = 0\n",
        "        min_validation_loss = validation_loss\n",
        "\n",
        "        # if there is a checkpoint file, remove it\n",
        "        if min_validation_path is not None:\n",
        "            os.remove(min_validation_path)\n",
        "\n",
        "        # save the new checkpoint file\n",
        "        min_validation_path = os.path.join(model_serial_path,\n",
        "                                           \"min_validation_loss:\" + str(min_validation_loss) + \"_epoch:\" + str(\n",
        "                                               epoch) + \".pth\")\n",
        "        torch.save(model, min_validation_path)\n",
        "    else:\n",
        "        early_stop_step += 1\n",
        "\n",
        "    # log the losses, and append to the lists\n",
        "    print(\n",
        "        f\"Epoch: {epoch + 1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\",\n",
        "        flush=True)\n",
        "    train_losses.append(averaged_training_loss.item())\n",
        "    validation_losses.append(validation_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    # check for early stopping\n",
        "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
        "        print(\"early stopping...\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.628308081Z"
        },
        "id": "eKRtlkFfGFxO"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, color='blue', label='Train Loss')\n",
        "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp8U_4eQGFxO"
      },
      "source": [
        "## Testing Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-10T15:52:40.630076269Z",
          "start_time": "2025-01-10T15:52:40.629125510Z"
        },
        "id": "POb_wAaHGFxP"
      },
      "outputs": [],
      "source": [
        "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
        "loaded_model = torch.load(min_validation_path)\n",
        "loaded_model = loaded_model.eval()\n",
        "\n",
        "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
        "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
        "class_correct, class_total = [0, 0], [0, 0]\n",
        "with torch.no_grad():\n",
        "    if APPLY_AUGMENTATION:\n",
        "        full_dataset.disable_augmentation()\n",
        "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
        "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "\n",
        "        test_outputs = loaded_model(test_images.type(torch.float))\n",
        "\n",
        "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
        "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
        "        test_outputs[test_outputs < THRESHOLD] = 0\n",
        "\n",
        "        # calculate indices for correct predictions\n",
        "        correct = (test_outputs == test_labels).squeeze()\n",
        "        for e, label in enumerate(test_labels):\n",
        "            # increase the correct prediction count for that label\n",
        "            class_correct[label] += correct[e].item()\n",
        "            class_total[label] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-01-10T15:52:40.629693529Z"
        },
        "id": "XfY5BWAOGFxP"
      },
      "outputs": [],
      "source": [
        "# Total: accuracy for whole dataset\n",
        "print(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\")\n",
        "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\")\n",
        "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\")\n",
        "\n",
        "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
        "    txt.write(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
        "    txt.write(\n",
        "        f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\\n\")\n",
        "    txt.write(\n",
        "        f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\\n\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}