{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C--R-ap6Hjdl"
   },
   "source": [
    "Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxDGWOBxHhDM"
   },
   "outputs": [],
   "source": [
    "# Clone the GitHub repository to the local environment\n",
    "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
    "\n",
    "# Import the sys module to modify the Python path\n",
    "import sys\n",
    "\n",
    "# Add the \"scripts\" directory to the Python path so that Python can access the modules in that directory\n",
    "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17a-EaHYRx-v"
   },
   "source": [
    "Drive Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDTCkZdjR0Wk"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (for data storage and access to dataset)\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDNJTrpeGFxF"
   },
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wr-lhh-GFxI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.897440108Z",
     "start_time": "2025-01-10T15:50:56.799530900Z"
    },
    "id": "hKYYLTpVGFxI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from models import MobileNetV2\n",
    "from bleeding_dataset import BleedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfnDKDTCGFxJ"
   },
   "source": [
    "## Training Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaqLtj46GFxK"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.919580790Z",
     "start_time": "2025-01-10T15:50:57.913228018Z"
    },
    "id": "Zphq5_ivGFxK"
   },
   "outputs": [],
   "source": [
    "# Define the path where model checkpoints and results will be saved\n",
    "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
    "\n",
    "# Define the train/test split ratio\n",
    "TRAIN_TEST_SPLIT = (0.8, 0.1)  # remaining parts will be used for testing\n",
    "\n",
    "# Set the directory path for the dataset\n",
    "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
    "\n",
    "# Set the batch size for training\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Define the learning rate for the optimizer\n",
    "LR = 0.001  # learning rate\n",
    "\n",
    "# Number of epochs to train the model\n",
    "NUM_OF_EPOCHS = 20\n",
    "\n",
    "# Early stopping limit: number of epochs with no improvement before stopping\n",
    "EARLY_STOP_LIMIT = 3\n",
    "\n",
    "# Threshold for predicting bleeding or healthy: values above this threshold are considered bleeding\n",
    "THRESHOLD = 0.5  # predictions above this threshold will be considered as bleeding\n",
    "\n",
    "# Select the model architecture: MobileNetV2, ResNet, AlexNet, or VGG19\n",
    "MODEL = MobileNetV2  # Options: ResNet, AlexNet, VGG19\n",
    "\n",
    "# Whether to apply data augmentation during training\n",
    "APPLY_AUGMENTATION = False\n",
    "\n",
    "# Whether to use cosine annealing for learning rate scheduling\n",
    "USE_COSINE_ANNEALING_LR = True\n",
    "\n",
    "# Number of times to augment each image during training\n",
    "AUGMENT_TIMES = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs8keuueGFxL"
   },
   "source": [
    "### Dataset, Model etc. Inıtıalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:58.526936237Z",
     "start_time": "2025-01-10T15:50:57.920838409Z"
    },
    "id": "LkLRM6CyGFxL"
   },
   "outputs": [],
   "source": [
    "# Set the device for training (CUDA if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()  # Clear any cached memory on the GPU (if using CUDA)\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "def initialize_model(model_class, save_path: str):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    :param model_class: \n",
    "    :param save_path: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Initialize the model class and move it to the appropriate device (GPU/CPU)\n",
    "    model = model_class().to(device)\n",
    "\n",
    "    # Generate a serial number based on the model name and current timestamp for saving\n",
    "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
    "\n",
    "    # Set the path where the model will be saved during training\n",
    "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
    "\n",
    "    # Create the directory for saving the model if it doesn't exist\n",
    "    os.makedirs(model_serial_path, exist_ok=True)\n",
    "\n",
    "    return model, model_serial_path\n",
    "\n",
    "# Initialize the model and get the save path for training\n",
    "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
    "\n",
    "# Placeholder for the full dataset (initialized later)\n",
    "full_dataset = None\n",
    "\n",
    "\n",
    "# Dataset Preparation\n",
    "def prepare_datasets(dataset_class, directory: str, split_ratios: list[int], batch_size: int, image_mode: str = \"RGB\", seed: int = 0):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    :param dataset_class: \n",
    "    :param directory: \n",
    "    :param split_ratios: \n",
    "    :param batch_size: \n",
    "    :param image_mode: \n",
    "    :param seed: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    global full_dataset\n",
    "    # Load the full dataset with augmentation settings\n",
    "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=APPLY_AUGMENTATION,\n",
    "                                 augment_times=AUGMENT_TIMES)\n",
    "\n",
    "    # Calculate the sizes of the train, test, and validation sets\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(split_ratios[0] * total_size)\n",
    "    test_size = int(split_ratios[1] * total_size)\n",
    "    validation_size = total_size - train_size - test_size\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset,\n",
    "                                                                   [train_size, validation_size, test_size])\n",
    "\n",
    "    # Oversample the bleeding class in the training set (for class imbalance handling)\n",
    "    train_labels = np.array(full_dataset.get_labels())[train_dataset.indices]\n",
    "    class_counts = np.bincount(train_labels)  # Count occurrences of each class (0 = healthy, 1 = bleeding)\n",
    "    class_weights = 1.0 / class_counts  # Compute inverse class frequencies\n",
    "\n",
    "    # Calculate weights for each sample based on its label\n",
    "    weights = [class_weights[label] for label in train_labels]\n",
    "\n",
    "    # Create a sampler to enforce the class weights during training\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    # Return the DataLoaders for the train, validation, and test datasets\n",
    "    return {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
    "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4,\n",
    "                                 pin_memory=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    }\n",
    "\n",
    "# Prepare the datasets and generate DataLoader objects for train, validation, and test sets\n",
    "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
    "\n",
    "# Calculate the weight for the bleeding class to handle class imbalance\n",
    "bleeding_weight = 6161 / (713 * AUGMENT_TIMES) if APPLY_AUGMENTATION else 6161 / 713\n",
    "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
    "\n",
    "# Define the loss function with a positive weight for the bleeding class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
    "\n",
    "# Initialize the optimizer for training (Adam optimizer)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Choose the learning rate scheduler based on whether cosine annealing is enabled\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_OF_EPOCHS) if USE_COSINE_ANNEALING_LR else lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbWFmh3zGFxM"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.628953950Z",
     "start_time": "2025-01-10T15:50:58.526428978Z"
    },
    "id": "VSFLnQOzGFxN"
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "\n",
    "# Lists to keep track of the training and validation losses over epochs\n",
    "train_losses, validation_losses = [], []\n",
    "\n",
    "# Variables for early stopping (to stop training if the validation loss does not improve)\n",
    "min_validation_loss = None  # minimum achieved loss on validation dataset, used for early stopping\n",
    "min_validation_path = None  # path to model checkpoint file\n",
    "early_stop_step = 0  # number of epochs since the last improvement in validation loss\n",
    "\n",
    "# Loop over the number of epochs\n",
    "for epoch in range(NUM_OF_EPOCHS):\n",
    "    # Enable data augmentation if specified\n",
    "    if APPLY_AUGMENTATION:\n",
    "        full_dataset.enable_augmentation()\n",
    "\n",
    "    averaged_training_loss = 0  # variable to track the cumulative training loss for this epoch\n",
    "\n",
    "    # Training loop over batches of the training dataset\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)  # move data to the appropriate device (GPU/CPU)\n",
    "\n",
    "        model = model.train()  # set model to training mode\n",
    "        outputs = model(images.type(torch.float))  # get model outputs (predictions)\n",
    "\n",
    "        # Extract the predictions and labels for loss calculation\n",
    "        float_outputs = outputs[:, 0].type(torch.float)\n",
    "        float_labels = labels.type(torch.float)\n",
    "\n",
    "        # Calculate the training loss using BCEWithLogitsLoss\n",
    "        train_loss = criterion(float_outputs, float_labels)\n",
    "        averaged_training_loss = averaged_training_loss + train_loss  # accumulate the loss\n",
    "\n",
    "        optimizer.zero_grad()  # clear previous gradients\n",
    "        train_loss.backward()  # compute gradients for backpropagation\n",
    "        optimizer.step()  # update model weights\n",
    "\n",
    "    # Calculate the average training loss for this epoch\n",
    "    averaged_training_loss = averaged_training_loss / len(data_loaders['train'])\n",
    "\n",
    "    # Validation loop (no gradients needed here, so use torch.no_grad())\n",
    "    with torch.no_grad():\n",
    "        if APPLY_AUGMENTATION:\n",
    "            full_dataset.disable_augmentation()  # turn off augmentation during validation\n",
    "\n",
    "        model = model.eval()  # set model to evaluation mode\n",
    "\n",
    "        # Calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for validation_images, validation_labels in data_loaders['validation']:\n",
    "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
    "\n",
    "            # Get the model's predictions for the validation data\n",
    "            validation_outputs = model(validation_images.type(torch.float))\n",
    "\n",
    "            # Extract the predictions and labels for loss calculation\n",
    "            float_validation_outputs = validation_outputs[:, 0].type(torch.float)\n",
    "            float_validation_labels = validation_labels.type(torch.float)\n",
    "\n",
    "            # Add the loss for this batch to the total validation loss\n",
    "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
    "\n",
    "        # Average the validation loss over the entire validation set\n",
    "        validation_loss /= len(data_loaders['validation'])\n",
    "\n",
    "    # If this is the first validation or a new minimum validation loss is achieved\n",
    "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
    "        early_stop_step = 0  # reset early stopping counter\n",
    "        min_validation_loss = validation_loss  # update minimum validation loss\n",
    "\n",
    "        # If there is a checkpoint from the previous best model, remove it\n",
    "        if min_validation_path is not None:\n",
    "            os.remove(min_validation_path)\n",
    "\n",
    "        # Save the current model as a checkpoint with the new minimum validation loss\n",
    "        min_validation_path = os.path.join(model_serial_path,\n",
    "                                           \"min_validation_loss:\" + str(min_validation_loss) + \"_epoch:\" + str(\n",
    "                                               epoch) + \".pth\")\n",
    "        torch.save(model, min_validation_path)\n",
    "    else:\n",
    "        # Increment early stopping counter if validation loss did not improve\n",
    "        early_stop_step += 1\n",
    "\n",
    "    # Log the losses and append them to the respective lists\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\",\n",
    "        flush=True)\n",
    "    train_losses.append(averaged_training_loss.item())\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    # Adjust the learning rate based on the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Check if early stopping should be triggered (if validation loss hasn't improved for several epochs)\n",
    "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
    "        print(\"early stopping...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.628308081Z"
    },
    "id": "eKRtlkFfGFxO"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp8U_4eQGFxO"
   },
   "source": [
    "## Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.630076269Z",
     "start_time": "2025-01-10T15:52:40.629125510Z"
    },
    "id": "POb_wAaHGFxP"
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "loaded_model = torch.load(min_validation_path)\n",
    "loaded_model = loaded_model.eval()\n",
    "\n",
    "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
    "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
    "class_correct, class_total = [0, 0], [0, 0]\n",
    "with torch.no_grad():\n",
    "    if APPLY_AUGMENTATION:\n",
    "        full_dataset.disable_augmentation()\n",
    "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        test_outputs = loaded_model(test_images.type(torch.float))\n",
    "\n",
    "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
    "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
    "        test_outputs[test_outputs < THRESHOLD] = 0\n",
    "\n",
    "        # calculate indices for correct predictions\n",
    "        correct = (test_outputs == test_labels).squeeze()\n",
    "        for e, label in enumerate(test_labels):\n",
    "            # increase the correct prediction count for that label\n",
    "            class_correct[label] += correct[e].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.629693529Z"
    },
    "id": "XfY5BWAOGFxP"
   },
   "outputs": [],
   "source": [
    "# Total: accuracy for whole dataset\n",
    "# Print out the total accuracy for the entire dataset by summing up the correct predictions and dividing by the total number of samples\n",
    "print(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\")\n",
    "\n",
    "# Print accuracy for healthy detection (class 0)\n",
    "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\")\n",
    "\n",
    "# Print accuracy for bleeding detection (class 1)\n",
    "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\")\n",
    "\n",
    "# Save the accuracy results to a text file in the model's directory\n",
    "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
    "    # Write total accuracy to the file\n",
    "    txt.write(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
    "\n",
    "    # Write healthy detection accuracy to the file\n",
    "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\\n\")\n",
    "\n",
    "    # Write bleeding detection accuracy to the file\n",
    "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\\n\")\n",
    "\n",
    "# Clear the GPU memory cache after evaluation to avoid memory overflow\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
