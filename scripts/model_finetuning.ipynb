{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C--R-ap6Hjdl"
   },
   "source": [
    "Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxDGWOBxHhDM"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17a-EaHYRx-v"
   },
   "source": [
    "Drive Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDTCkZdjR0Wk"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (for data storage and access to dataset)\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDNJTrpeGFxF"
   },
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wr-lhh-GFxI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.897440108Z",
     "start_time": "2025-01-10T15:50:56.799530900Z"
    },
    "id": "hKYYLTpVGFxI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from models import MobileNetV2\n",
    "from bleeding_dataset import BleedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfnDKDTCGFxJ"
   },
   "source": [
    "## Training Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Configuration\n",
    "\n",
    "This section defines the key hyperparameters and settings for training the model.\n",
    "\n",
    "- **SAVE_PATH:** Directory where model checkpoints and training results will be saved.\n",
    "- **TRAIN_TEST_SPLIT:** Specifies the ratio for training and validation data. The remaining portion will be used for testing.\n",
    "- **DIRECTORY_PATH:** Location of the dataset used for training and evaluation.\n",
    "- **BATCH_SIZE:** Number of samples processed in each training step.\n",
    "- **LR (Learning Rate):** The step size used by the optimizer to update model weights.\n",
    "- **NUM_OF_EPOCHS:** Total number of training iterations over the dataset.\n",
    "- **EARLY_STOP_LIMIT:** The number of epochs without improvement before stopping training.\n",
    "- **THRESHOLD:** Classification threshold for predicting bleeding images.\n",
    "- **MODEL:** Specifies which deep learning architecture to use (MobileNetV2, ResNet, AlexNet, or VGG19).\n",
    "- **APPLY_AUGMENTATION:** Determines whether to apply data augmentation to handle class imbalance.\n",
    "- **USE_COSINE_ANNEALING_LR:** Enables cosine annealing for learning rate adjustment.\n",
    "- **AUGMENT_TIMES:** Number of times each image is augmented during training.\n",
    "\n",
    "Adjust these parameters as needed to optimize model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaqLtj46GFxK"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.919580790Z",
     "start_time": "2025-01-10T15:50:57.913228018Z"
    },
    "id": "Zphq5_ivGFxK"
   },
   "outputs": [],
   "source": [
    "# Path to save model checkpoints and results\n",
    "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
    "\n",
    "# Train/test split ratio\n",
    "TRAIN_TEST_SPLIT = (0.8, 0.1)  \n",
    "\n",
    "# Dataset directory path\n",
    "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "NUM_OF_EPOCHS = 20\n",
    "EARLY_STOP_LIMIT = 3\n",
    "THRESHOLD = 0.5  \n",
    "\n",
    "# Model selection\n",
    "MODEL = MobileNetV2  \n",
    "\n",
    "# Training settings\n",
    "APPLY_AUGMENTATION = False\n",
    "USE_COSINE_ANNEALING_LR = True\n",
    "AUGMENT_TIMES = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs8keuueGFxL"
   },
   "source": [
    "### Dataset, Model etc. Inıtıalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization and Dataset Preparation\n",
    "\n",
    "This section initializes the model, prepares the dataset, and configures the training parameters.\n",
    "\n",
    "- **Device Selection:** Automatically selects CUDA if available, otherwise defaults to CPU.\n",
    "- **Model Initialization:** Loads the selected model architecture and assigns a unique serial number for saving checkpoints.\n",
    "- **Dataset Preparation:** \n",
    "  - Splits the dataset into training, validation, and test sets based on predefined ratios.\n",
    "  - Applies optional augmentation to balance class distribution.\n",
    "  - Uses a **WeightedRandomSampler** to address class imbalance.\n",
    "- **Loss Function:** Uses **BCEWithLogitsLoss** with class weighting to ensure bleeding images are properly accounted for.\n",
    "- **Optimizer and Scheduler:** \n",
    "  - Uses **Adam** optimizer for efficient parameter updates.\n",
    "  - Supports either **Cosine Annealing LR** or **StepLR** scheduling for dynamic learning rate adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:58.526936237Z",
     "start_time": "2025-01-10T15:50:57.920838409Z"
    },
    "id": "LkLRM6CyGFxL"
   },
   "outputs": [],
   "source": [
    "# Set device (CUDA if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model Initialization\n",
    "def initialize_model(model_class, save_path: str):\n",
    "    \"\"\"\n",
    "    Initializes the model and creates a directory for saving checkpoints.\n",
    "\n",
    "    :param model_class: Model architecture to be used (MobileNetV2, ResNet, etc.)\n",
    "    :param save_path: Directory where model checkpoints will be saved.\n",
    "    :return: Initialized model and save path.\n",
    "    \"\"\"\n",
    "    model = model_class().to(device)\n",
    "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
    "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
    "    os.makedirs(model_serial_path, exist_ok=True)\n",
    "\n",
    "    return model, model_serial_path\n",
    "\n",
    "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
    "full_dataset = None  # Placeholder for dataset\n",
    "\n",
    "\n",
    "# Dataset Preparation\n",
    "def prepare_datasets(dataset_class, directory: str, split_ratios: list[int], batch_size: int, image_mode: str = \"RGB\", seed: int = 0):\n",
    "    \"\"\"\n",
    "    Prepares train, validation, and test datasets.\n",
    "\n",
    "    :param dataset_class: Dataset class to be used (e.g., BleedDataset)\n",
    "    :param directory: Path to dataset directory\n",
    "    :param split_ratios: Ratios for train, validation, and test splits\n",
    "    :param batch_size: Number of samples per batch\n",
    "    :param image_mode: Image format (\"RGB\" or \"gray\")\n",
    "    :param seed: Random seed for reproducibility\n",
    "    :return: Dictionary containing DataLoaders for train, validation, and test sets\n",
    "    \"\"\"\n",
    "    global full_dataset\n",
    "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=APPLY_AUGMENTATION, augment_times=AUGMENT_TIMES)\n",
    "    \n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(split_ratios[0] * total_size)\n",
    "    test_size = int(split_ratios[1] * total_size)\n",
    "    validation_size = total_size - train_size - test_size\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "    train_labels = np.array(full_dataset.get_labels())[train_dataset.indices]\n",
    "    class_counts = np.bincount(train_labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    weights = [class_weights[label] for label in train_labels]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    return {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
    "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    }\n",
    "\n",
    "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
    "\n",
    "# Class Weight Calculation for Imbalance Handling\n",
    "bleeding_weight = 6161 / (713 * AUGMENT_TIMES) if APPLY_AUGMENTATION else 6161 / 713\n",
    "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_OF_EPOCHS) if USE_COSINE_ANNEALING_LR else lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbWFmh3zGFxM"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Process\n",
    "\n",
    "This section implements the full training loop, including validation and early stopping.\n",
    "\n",
    "### Training Workflow:\n",
    "- **Data Augmentation:** Enabled during training, disabled for validation.\n",
    "- **Training Loop:**\n",
    "  - Iterates over training batches, computes predictions, and updates weights.\n",
    "  - Uses **Binary Cross Entropy with Logits Loss (BCEWithLogitsLoss)** as the loss function.\n",
    "- **Validation Loop:**\n",
    "  - Runs without gradient calculations to evaluate model performance.\n",
    "  - Computes validation loss to track progress.\n",
    "- **Checkpointing:**\n",
    "  - Saves the model whenever a new minimum validation loss is achieved.\n",
    "  - Deletes the previous best checkpoint before saving a new one.\n",
    "- **Early Stopping:**\n",
    "  - Monitors validation loss and stops training if no improvement occurs for `EARLY_STOP_LIMIT` epochs.\n",
    "- **Learning Rate Adjustment:**\n",
    "  - The learning rate is updated according to the selected scheduler (Cosine Annealing or StepLR).\n",
    "\n",
    "This ensures efficient training while preventing overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.628953950Z",
     "start_time": "2025-01-10T15:50:58.526428978Z"
    },
    "id": "VSFLnQOzGFxN"
   },
   "outputs": [],
   "source": [
    "# Training Initialization\n",
    "train_losses, validation_losses = [], []\n",
    "min_validation_loss, min_validation_path = None, None\n",
    "early_stop_step = 0  \n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(NUM_OF_EPOCHS):\n",
    "    if APPLY_AUGMENTATION:\n",
    "        full_dataset.enable_augmentation()\n",
    "\n",
    "    averaged_training_loss = 0  \n",
    "\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "        \n",
    "        model.train()\n",
    "        outputs = model(images.type(torch.float))\n",
    "\n",
    "        float_outputs = outputs[:, 0].type(torch.float)\n",
    "        float_labels = labels.type(torch.float)\n",
    "\n",
    "        train_loss = criterion(float_outputs, float_labels)\n",
    "        averaged_training_loss += train_loss  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    averaged_training_loss /= len(data_loaders['train'])\n",
    "\n",
    "    # Validation Loop\n",
    "    with torch.no_grad():\n",
    "        if APPLY_AUGMENTATION:\n",
    "            full_dataset.disable_augmentation()\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        for validation_images, validation_labels in data_loaders['validation']:\n",
    "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
    "            validation_outputs = model(validation_images.type(torch.float))\n",
    "\n",
    "            float_validation_outputs = validation_outputs[:, 0].type(torch.float)\n",
    "            float_validation_labels = validation_labels.type(torch.float)\n",
    "\n",
    "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
    "\n",
    "        validation_loss /= len(data_loaders['validation'])\n",
    "\n",
    "    # Model Checkpointing\n",
    "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
    "        early_stop_step = 0\n",
    "        min_validation_loss = validation_loss  \n",
    "\n",
    "        if min_validation_path:\n",
    "            os.remove(min_validation_path)\n",
    "\n",
    "        min_validation_path = os.path.join(model_serial_path, f\"min_validation_loss:{min_validation_loss}_epoch:{epoch}.pth\")\n",
    "        torch.save(model, min_validation_path)\n",
    "    else:\n",
    "        early_stop_step += 1\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\", flush=True)\n",
    "    \n",
    "    train_losses.append(averaged_training_loss.item())\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
    "        print(\"early stopping...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.628308081Z"
    },
    "id": "eKRtlkFfGFxO"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp8U_4eQGFxO"
   },
   "source": [
    "## Testing Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Evaluation\n",
    "\n",
    "This section loads the best-performing model and evaluates its accuracy on the test set.\n",
    "\n",
    "### Testing Workflow:\n",
    "- **Load Best Model:** The checkpoint with the lowest validation loss is loaded.\n",
    "- **Disable Augmentation:** Ensures consistency in test data.\n",
    "- **Inference:**\n",
    "  - Runs the model on test images in evaluation mode.\n",
    "  - Applies the classification threshold to determine predictions.\n",
    "- **Performance Calculation:**\n",
    "  - Tracks correct predictions separately for each class (bleeding vs. healthy).\n",
    "  - Computes the total number of samples per class.\n",
    "\n",
    "This step provides a final assessment of model performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.630076269Z",
     "start_time": "2025-01-10T15:52:40.629125510Z"
    },
    "id": "POb_wAaHGFxP"
   },
   "outputs": [],
   "source": [
    "# Load best model and set to evaluation mode\n",
    "loaded_model = torch.load(min_validation_path)\n",
    "loaded_model = loaded_model.eval()\n",
    "\n",
    "# Initialize counters for correct predictions per class\n",
    "class_correct, class_total = [0, 0], [0, 0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    if APPLY_AUGMENTATION:\n",
    "        full_dataset.disable_augmentation()\n",
    "\n",
    "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        test_outputs = loaded_model(test_images.type(torch.float))\n",
    "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
    "\n",
    "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
    "        test_outputs[test_outputs < THRESHOLD] = 0\n",
    "\n",
    "        correct = (test_outputs == test_labels).squeeze()\n",
    "\n",
    "        for e, label in enumerate(test_labels):\n",
    "            class_correct[label] += correct[e].item()\n",
    "            class_total[label] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation\n",
    "\n",
    "This section calculates and displays the model's accuracy on the test dataset.\n",
    "\n",
    "### Accuracy Metrics:\n",
    "- **Total Accuracy:** Overall percentage of correctly classified images.\n",
    "- **Healthy Detection Accuracy:** The proportion of correctly classified healthy images.\n",
    "- **Bleeding Detection Accuracy:** The proportion of correctly classified bleeding images.\n",
    "\n",
    "### Saving Results:\n",
    "- The accuracy metrics are saved in a text file inside the model's directory for future reference.\n",
    "\n",
    "### GPU Memory Management:\n",
    "- Clears the GPU memory cache after evaluation to free up resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.629693529Z"
    },
    "id": "XfY5BWAOGFxP"
   },
   "outputs": [],
   "source": [
    "# Compute and print accuracy metrics\n",
    "print(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\")\n",
    "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\")\n",
    "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\")\n",
    "\n",
    "# Save accuracy results to a text file\n",
    "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
    "    txt.write(f\"Total accuracy: {sum(class_correct) / sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
    "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0] / class_total[0]}\\n\")\n",
    "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1] / class_total[1]}\\n\")\n",
    "\n",
    "# Clear GPU memory cache after evaluation\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
