{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Google Colab Setup"
   ],
   "metadata": {
    "id": "C--R-ap6Hjdl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/jan1na/Bleeding-Detecting-on-Capsule-Endoscopy.git\n",
    "\n",
    "%cd Bleeding-Detecting-on-Capsule-Endoscopy\n",
    "!git checkout \"janina\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/Bleeding-Detecting-on-Capsule-Endoscopy/scripts')"
   ],
   "metadata": {
    "id": "UxDGWOBxHhDM",
    "outputId": "d63f624c-fc23-479d-82ab-16b1ba99a83d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Bleeding-Detecting-on-Capsule-Endoscopy'...\n",
      "remote: Enumerating objects: 70, done.\u001B[K\n",
      "remote: Counting objects: 100% (70/70), done.\u001B[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001B[K\n",
      "remote: Total 70 (delta 36), reused 43 (delta 16), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (70/70), 4.78 MiB | 36.23 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n",
      "/content/Bleeding-Detecting-on-Capsule-Endoscopy/Bleeding-Detecting-on-Capsule-Endoscopy/Bleeding-Detecting-on-Capsule-Endoscopy/Bleeding-Detecting-on-Capsule-Endoscopy/Bleeding-Detecting-on-Capsule-Endoscopy\n",
      "Branch 'janina' set up to track remote branch 'janina' from 'origin'.\n",
      "Switched to a new branch 'janina'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drive Setup"
   ],
   "metadata": {
    "id": "17a-EaHYRx-v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (for data storage)\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "SDTCkZdjR0Wk",
    "outputId": "bbb48eb3-8253-4edf-85b2-5239fa3d2125",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDNJTrpeGFxF"
   },
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8R9IP-WGFxH"
   },
   "source": [
    "## TODO\n",
    "* losses should be weighted for different classes, there are 8 to 9 times of healthy images than there is for bleeding, so model will be inclined to predict healthy\n",
    "* hyperparameters for deep learning runs should be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wr-lhh-GFxI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.897440108Z",
     "start_time": "2025-01-10T15:50:56.799530900Z"
    },
    "id": "hKYYLTpVGFxI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from models import MobileNetV2, GoogleNet, ResNet, AlexNet, VGG19\n",
    "from bleeding_dataset import BleedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfnDKDTCGFxJ"
   },
   "source": [
    "## Training Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaqLtj46GFxK"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.919580790Z",
     "start_time": "2025-01-10T15:50:57.913228018Z"
    },
    "id": "Zphq5_ivGFxK"
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/runs/\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
    "DIRECTORY_PATH = \"/content/drive/MyDrive/Colab Notebooks/DL4MI/project_capsule_dataset\"\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001 # learning rate\n",
    "\n",
    "NUM_OF_EPOCHS = 20\n",
    "EARLY_STOP_LIMIT = 3\n",
    "\n",
    "THRESHOLD = 0.5 # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction\n",
    "MODEL =  ResNet\n",
    "AUGMENT_TIMES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs8keuueGFxL"
   },
   "source": [
    "### Dataset, Model etc. Inıtıalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:58.526936237Z",
     "start_time": "2025-01-10T15:50:57.920838409Z"
    },
    "id": "LkLRM6CyGFxL"
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- MODEL & DATASET ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model Initialization\n",
    "def initialize_model(model_class, save_path):\n",
    "    model = model_class().to(device)\n",
    "    model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
    "    model_serial_path = os.path.join(save_path, model_serial_number)\n",
    "    os.makedirs(model_serial_path, exist_ok=True)\n",
    "    return model, model_serial_path\n",
    "\n",
    "model, model_serial_path = initialize_model(MODEL, SAVE_PATH)\n",
    "\n",
    "# Dataset Preparation\n",
    "def prepare_datasets(dataset_class, directory, split_ratios, batch_size, image_mode=\"RGB\", seed=0):\n",
    "    full_dataset = dataset_class(directory, mode=image_mode, apply_augmentation=False)\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(split_ratios[0] * total_size)\n",
    "    test_size = int(split_ratios[1] * total_size)\n",
    "    validation_size = total_size - train_size - test_size\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(full_dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "    # Apply augmentation **only to the training set**\n",
    "    train_dataset.dataset.enable_augmentation(augment_times=AUGMENT_TIMES)\n",
    "\n",
    "    # Oversampling for bleeding images\n",
    "    labels = [label for _, label in train_dataset.dataset.data]\n",
    "    class_counts = np.bincount(labels)  # Count occurrences per class\n",
    "    class_weights = 1.0 / class_counts  # Inverse class frequency\n",
    "\n",
    "    weights = [class_weights[label] for _, label in train_dataset.dataset.data]\n",
    "    sampler = WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "    return {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=4, pin_memory=True, sampler=sampler),\n",
    "        \"validation\": DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    }\n",
    "\n",
    "data_loaders = prepare_datasets(BleedDataset, DIRECTORY_PATH, TRAIN_TEST_SPLIT, BATCH_SIZE, image_mode=\"RGB\", seed=0)\n",
    "\n",
    "# Penalty for imbalanced dataset\n",
    "bleeding_weight = 6161 / (713 * AUGMENT_TIMES)\n",
    "weights = torch.tensor([1.0, bleeding_weight]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
    "\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_OF_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbWFmh3zGFxM"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.628953950Z",
     "start_time": "2025-01-10T15:50:58.526428978Z"
    },
    "id": "VSFLnQOzGFxN",
    "outputId": "6303f03c-a1c7-4ae6-e624-c542484667c3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n                         ~~~~~~~~~~~~^^^^^\nIndexError: list index out of range\n",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-e4b96eead9f6>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mNUM_OF_EPOCHS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0maveraged_training_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_loaders\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mleave\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1181\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1182\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1183\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    699\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    700\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 701\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    702\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    703\u001B[0m             if (\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1463\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1464\u001B[0m                 \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_task_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1465\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1466\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1467\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1489\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1490\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExceptionWrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1491\u001B[0;31m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1492\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1493\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    713\u001B[0m             \u001B[0;31m# instantiate since we don't know how to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    714\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 715\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    716\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    717\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n                         ~~~~~~~~~~~~^^^^^\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "train_losses, validation_losses = [], []\n",
    "min_validation_loss = None # minimum achieved loss on validation dataset, used for early stopping\n",
    "min_validation_path = None # path to model checkpoint file\n",
    "early_stop_step = 0\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCHS):\n",
    "    averaged_training_loss = 0\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(data_loaders['train']), leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        model = model.train()\n",
    "        outputs = model(images.type(torch.float))\n",
    "\n",
    "        float_outputs = outputs[:,0].type(torch.float)\n",
    "        float_labels = labels.type(torch.float)\n",
    "        train_loss = criterion(float_outputs, float_labels)\n",
    "        averaged_training_loss = averaged_training_loss + train_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculating the average loss in this epoch's training loop\n",
    "    averaged_training_loss = averaged_training_loss / len(data_loaders['train'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "\n",
    "        # calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for validation_images, validation_labels in data_loaders['validation']:\n",
    "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
    "\n",
    "            validation_outputs = model(validation_images.type(torch.float))\n",
    "\n",
    "            float_validation_outputs = validation_outputs[:,0].type(torch.float)\n",
    "            float_validation_labels = validation_labels.type(torch.float)\n",
    "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
    "\n",
    "        # and average the loss over dataset length\n",
    "        validation_loss /= len(data_loaders['validation'])\n",
    "\n",
    "    # if this is first validation or a new minimum is achieved\n",
    "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
    "        early_stop_step = 0\n",
    "        min_validation_loss = validation_loss\n",
    "\n",
    "        # if there is a checkpoint file, remove it\n",
    "        if min_validation_path is not None:\n",
    "            os.remove(min_validation_path)\n",
    "\n",
    "        # save the new checkpoint file\n",
    "        min_validation_path = os.path.join(model_serial_path, \"min_validation_loss:\"+str(min_validation_loss) + \"_epoch:\" + str(epoch) + \".pth\")\n",
    "        torch.save(model, min_validation_path)\n",
    "    else:\n",
    "        early_stop_step += 1\n",
    "\n",
    "    # log the losses, and append to the lists\n",
    "    print(f\"Epoch: {epoch+1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\", flush=True)\n",
    "    train_losses.append(averaged_training_loss.item())\n",
    "    validation_losses.append(validation_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    # check for early stopping\n",
    "    if early_stop_step >= EARLY_STOP_LIMIT:\n",
    "        print(\"early stopping...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.628308081Z"
    },
    "id": "eKRtlkFfGFxO"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp8U_4eQGFxO"
   },
   "source": [
    "## Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.630076269Z",
     "start_time": "2025-01-10T15:52:40.629125510Z"
    },
    "id": "POb_wAaHGFxP"
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "loaded_model = model.__class__().to(device)\n",
    "loaded_model.load_state_dict(torch.load(min_validation_path))\n",
    "loaded_model = loaded_model.eval()\n",
    "\n",
    "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
    "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
    "class_correct, class_total = [0,0], [0,0]\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in tqdm(data_loaders['test']):\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        test_outputs = loaded_model(test_images.type(torch.float))\n",
    "\n",
    "        test_outputs = test_outputs.squeeze().type(torch.float)\n",
    "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
    "        test_outputs[test_outputs < THRESHOLD] = 0\n",
    "\n",
    "        # calculate indices for correct predictions\n",
    "        correct = (test_outputs == test_labels).squeeze()\n",
    "        for e, label in enumerate(test_labels):\n",
    "            # increase the correct prediction count for that label\n",
    "            class_correct[label] += correct[e].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.629693529Z"
    },
    "id": "XfY5BWAOGFxP"
   },
   "outputs": [],
   "source": [
    "# Total: accuracy for whole dataset\n",
    "print(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\")\n",
    "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\")\n",
    "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\")\n",
    "\n",
    "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
    "    txt.write(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
    "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\\n\")\n",
    "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\\n\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
