{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* losses should be weighted for different classes, there are 8 to 9 times of healthy images than there is for bleeding, so model will be inclined to predict healthy\n",
    "* hyperparameters for deep learning runs should be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.897440108Z",
     "start_time": "2025-01-10T15:50:56.799530900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.901226144Z",
     "start_time": "2025-01-10T15:50:57.897308858Z"
    }
   },
   "outputs": [],
   "source": [
    "class BleedDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_read_func=\"RGB\"):\n",
    "        self.root_dir = root_dir\n",
    "        self.bleeding_dir = os.path.join(root_dir, \"bleeding\")\n",
    "        self.healthy_dir = os.path.join(root_dir, \"healthy\")\n",
    "\n",
    "        # get image paths\n",
    "        self.x = [os.path.join(self.bleeding_dir, p) for p in os.listdir(self.bleeding_dir)] + [os.path.join(self.healthy_dir, p) for p in os.listdir(self.healthy_dir)]\n",
    "        \n",
    "        # get image labels, bleeding=1, healthy=0\n",
    "        self.y = [1 for _ in os.listdir(self.bleeding_dir)] + [0 for _ in os.listdir(self.healthy_dir)]\n",
    "        self.num_samples = len(os.listdir(self.bleeding_dir)) + len(os.listdir(self.healthy_dir))\n",
    "\n",
    "        # set up the function to use for image reading\n",
    "        # different reading functions can be written and used with this structure\n",
    "        if image_read_func == \"RGB\":\n",
    "            self.image_read_function = self.read_RGB\n",
    "        elif image_read_func == \"gray\":\n",
    "            self.image_read_function = self.read_gray\n",
    "        else:\n",
    "            print(\"Wrong image_read_func parameter\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def read_RGB(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = [0,0,0] # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = [0,0,0] # painting the upper right corner if there is white text parts\n",
    "        image = np.transpose(image, [2,0,1]) # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def read_gray(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = 0 # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = 0 # painting the upper right corner if there is white text parts\n",
    "        image = image[np.newaxis, ...] # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_read_function(idx)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.918217402Z",
     "start_time": "2025-01-10T15:50:57.900811214Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 128, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 64, kernel_size=3)\n",
    "        self.drop5 = nn.Dropout2d(p=0.2)\n",
    "        self.conv6 = nn.Conv2d(64, 16, kernel_size=3)\n",
    "        self.drop6 = nn.Dropout2d(p=0.2)\n",
    "        self.relu = F.relu\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.fully_conv = nn.Conv2d(16, 1, kernel_size=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.max_pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.max_pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = self.max_pool(self.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        x = self.drop5(self.relu(self.conv5(x)))\n",
    "        x = self.drop6(self.relu(self.conv6(x)))\n",
    "        x = self.sigmoid(self.fully_conv(x))\n",
    "        \n",
    "        return x[:,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:57.919580790Z",
     "start_time": "2025-01-10T15:50:57.913228018Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = \"./\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
    "DIRECTORY_PATH = \"../project_capsule_dataset\"\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.001 # learning rate\n",
    "\n",
    "NUM_OF_EPOCHS = 1\n",
    "EARLY_STOP_LIMIT = 3\n",
    "\n",
    "THRESHOLD = 0.5 # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset, Model etc. Inıtıalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:50:58.526936237Z",
     "start_time": "2025-01-10T15:50:57.920838409Z"
    }
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- MODEL & DATASET ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = DummyModel().to(device)\n",
    "model_serial_number = f\"training_with_{model.__class__.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\"\n",
    "\n",
    "model_serial_path = os.path.join(SAVE_PATH, model_serial_number)\n",
    "os.makedirs(model_serial_path)\n",
    "\n",
    "dataset = BleedDataset(DIRECTORY_PATH, image_read_func=\"RGB\")\n",
    "\n",
    "train_size = int(TRAIN_TEST_SPLIT[0] * len(dataset))\n",
    "test_size = int(TRAIN_TEST_SPLIT[1] * len(dataset))\n",
    "validation_size = len(dataset) - train_size - test_size\n",
    "\n",
    "torch.manual_seed(0) # setting the seed to 0 so dataset split is same for every run\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "torch.manual_seed(hash(model_serial_number)) # changing the seed so each training is fully random everytime\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.628953950Z",
     "start_time": "2025-01-10T15:50:58.526428978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m     averaged_training_loss \u001B[38;5;241m=\u001B[39m averaged_training_loss \u001B[38;5;241m+\u001B[39m train_loss\n\u001B[1;32m     20\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 21\u001B[0m     \u001B[43mtrain_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# calculating the average loss in this epoch's training loop\u001B[39;00m\n",
      "File \u001B[0;32m~/Downloads/project/venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    580\u001B[0m     )\n\u001B[0;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Downloads/project/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Downloads/project/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TRAINING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "train_losses, validation_losses = [], []\n",
    "min_validation_loss = None # minimum achieved loss on validation dataset, used for early stopping\n",
    "min_validation_path = None # path to model checkpoint file\n",
    "early_stop_step = 0\n",
    "\n",
    "for epoch in range(NUM_OF_EPOCHS):\n",
    "    averaged_training_loss = 0\n",
    "    for batch_idx, (images, labels) in tqdm(enumerate(train_dataloader), leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        model = model.train()\n",
    "        outputs = model(images.type(torch.float))\n",
    "\n",
    "        float_outputs = outputs[:,0].type(torch.float)\n",
    "        float_labels = labels.type(torch.float)\n",
    "        train_loss = criterion(float_outputs, float_labels)\n",
    "        averaged_training_loss = averaged_training_loss + train_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculating the average loss in this epoch's training loop\n",
    "    averaged_training_loss = averaged_training_loss / len(train_dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        \n",
    "        # calculate validation loss\n",
    "        validation_loss = 0.0\n",
    "        for validation_images, validation_labels in validation_dataloader:\n",
    "            validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
    "\n",
    "            validation_outputs = model(validation_images.type(torch.float))\n",
    "\n",
    "            float_validation_outputs = validation_outputs[:,0].type(torch.float)\n",
    "            float_validation_labels = validation_labels.type(torch.float)\n",
    "            validation_loss += criterion(float_validation_outputs, float_validation_labels).item()\n",
    "\n",
    "        # and average the loss over dataset length\n",
    "        validation_loss /= len(validation_dataset)\n",
    "    \n",
    "    # if this is first validation or a new minimum is achieved\n",
    "    if min_validation_loss is None or validation_loss < min_validation_loss:\n",
    "        early_stop_step = 0\n",
    "        min_validation_loss = validation_loss\n",
    "        \n",
    "        # if there is a checkpoint file, remove it\n",
    "        if min_validation_path is not None:\n",
    "            os.remove(min_validation_path)\n",
    "        \n",
    "        # save the new checkpoint file\n",
    "        min_validation_path = os.path.join(model_serial_path, \"min_validation_loss:\"+str(min_validation_loss) + \"_epoch:\" + str(epoch) + \".pth\")\n",
    "        torch.save(model.state_dict(), min_validation_path)\n",
    "\n",
    "    # log the losses, and append to the lists\n",
    "    print(f\"Epoch: {epoch+1} | training loss: {averaged_training_loss.item()} | min validation loss: {min_validation_loss}\", flush=True)\n",
    "    train_losses.append(averaged_training_loss.item())\n",
    "    validation_losses.append(validation_loss)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # check for early stopping\n",
    "    early_stop_step = early_stop_step + 1\n",
    "    if early_stop_step == EARLY_STOP_LIMIT:\n",
    "        print(\"early stopping...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.628308081Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "plt.plot(validation_losses, color='orange', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(model_serial_path, \"losses.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.630076269Z",
     "start_time": "2025-01-10T15:52:40.629125510Z"
    }
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- TESTING ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "loaded_model = DummyModel().to(device)\n",
    "#loaded_model.load_state_dict(torch.load(min_validation_path))\n",
    "loaded_model = loaded_model.eval()\n",
    "\n",
    "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
    "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
    "class_correct, class_total = [0,0], [0,0]\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in tqdm(test_dataloader):\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        test_outputs = loaded_model(test_images.type(torch.float))\n",
    "        \n",
    "        test_outputs = test_outputs[:,0].type(torch.float)\n",
    "        test_outputs[test_outputs >= THRESHOLD] = 1\n",
    "        test_outputs[test_outputs < THRESHOLD] = 0\n",
    "\n",
    "        # calculate indices for correct predictions\n",
    "        correct = (test_outputs == test_labels).squeeze()\n",
    "        for e, label in enumerate(test_labels):\n",
    "            # increase the correct prediction count for that label\n",
    "            class_correct[label] += correct[e].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.629693529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total: accuracy for whole dataset\n",
    "print(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\")\n",
    "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\")\n",
    "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\")\n",
    "\n",
    "with open(os.path.join(model_serial_path, \"accuracy.txt\"), 'w') as txt:\n",
    "    txt.write(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
    "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\\n\")\n",
    "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\\n\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.632356116Z",
     "start_time": "2025-01-10T15:52:40.630388988Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import ConcatDataset, Dataset, DataLoader, random_split\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.631214137Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = \"./\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = (0.8, 0.1) # remaining parts will be test\n",
    "DIRECTORY_PATH = \"/home/mericdemirors/Desktop/TUD_lectures/DLMI/project/project_capsule_dataset\"\n",
    "\n",
    "THRESHOLD = 0.5 # predictions bigger than threshold will be counted as bleeding prediction, and lower ones will be healthy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.631861996Z"
    }
   },
   "outputs": [],
   "source": [
    "def function(image, parameter1, parameter2, parameter3):\n",
    "    return 0\n",
    "decision_function = function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673405858Z"
    }
   },
   "outputs": [],
   "source": [
    "decision_function_path = os.path.join(SAVE_PATH, f\"{decision_function.__name__}_{datetime.now().strftime('on_%m.%d._at_%H:%M:%S')}\")\n",
    "os.makedirs(decision_function_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:52:40.674908516Z",
     "start_time": "2025-01-10T15:52:40.673609807Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter1_values = [0, 1]\n",
    "parameter2_values = [2, 3]\n",
    "parameter3_values = [4]\n",
    "parameter_combinations = list(itertools.product(parameter1_values, parameter2_values, parameter3_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673729417Z"
    }
   },
   "outputs": [],
   "source": [
    "class BleedDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_read_func=\"RGB\"):\n",
    "        self.root_dir = root_dir\n",
    "        self.bleeding_dir = os.path.join(root_dir, \"bleeding\")\n",
    "        self.healthy_dir = os.path.join(root_dir, \"healthy\")\n",
    "\n",
    "        # get image paths\n",
    "        self.x = [os.path.join(self.bleeding_dir, p) for p in os.listdir(self.bleeding_dir)] + [os.path.join(self.healthy_dir, p) for p in os.listdir(self.healthy_dir)]\n",
    "        \n",
    "        # get image labels, bleeding=1, healthy=0\n",
    "        self.y = [1 for _ in os.listdir(self.bleeding_dir)] + [0 for _ in os.listdir(self.healthy_dir)]\n",
    "        self.num_samples = len(os.listdir(self.bleeding_dir)) + len(os.listdir(self.healthy_dir))\n",
    "\n",
    "        # set up the function to use for image reading\n",
    "        # different reading functions can be written and used with this structure\n",
    "        if image_read_func == \"RGB\":\n",
    "            self.image_read_function = self.read_RGB\n",
    "        elif image_read_func == \"gray\":\n",
    "            self.image_read_function = self.read_gray\n",
    "        else:\n",
    "            print(\"Wrong image_read_func parameter\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def read_RGB(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = [0,0,0] # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = [0,0,0] # painting the upper right corner if there is white text parts\n",
    "        image = np.transpose(image, [2,0,1]) # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def read_gray(self, idx):\n",
    "        path = self.x[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[32:544, 32:544] # cropping image to get rid of the black borders\n",
    "        image[:48,:48] = 0 # painting the upper left corner if there is a gray square\n",
    "        image[:31, 452:] = 0 # painting the upper right corner if there is white text parts\n",
    "        image = image[np.newaxis, ...] # adjust the axises into the pytorch dimensions of [B, C, W, H]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_read_function(idx)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673791527Z"
    }
   },
   "outputs": [],
   "source": [
    "### ---|---|---|---|---|---|---|---|---|---|--- DATASET SPLIT ---|---|---|---|---|---|---|---|---|---|--- ###\n",
    "dataset = BleedDataset(DIRECTORY_PATH, image_read_func=\"RGB\")\n",
    "\n",
    "train_size = int(TRAIN_TEST_SPLIT[0] * len(dataset))\n",
    "test_size = int(TRAIN_TEST_SPLIT[1] * len(dataset))\n",
    "validation_size = len(dataset) - train_size - test_size\n",
    "\n",
    "torch.manual_seed(0) # setting the seed to 0 so dataset split is same for every run\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "train_validation_dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "\n",
    "train_validation_dataloader = DataLoader(train_validation_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Generalizing Parameters (try out different parameter combinations on train_validation_dataset, and select the best one to try on test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673852807Z"
    }
   },
   "outputs": [],
   "source": [
    "total_accuracies = []\n",
    "healthy_accuracies = []\n",
    "bleeding_accuracies = []\n",
    "best_accuracy = 0\n",
    "best_parameter_combination = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673904417Z"
    }
   },
   "outputs": [],
   "source": [
    "for par_comb in parameter_combinations:\n",
    "    # class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
    "    # class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
    "    class_correct, class_total = [0,0], [0,0]\n",
    "\n",
    "    for image, label in tqdm(train_validation_dataloader):\n",
    "        decision = decision_function(image, *par_comb)\n",
    "        \n",
    "        class_total[label] += 1\n",
    "        if decision == label:\n",
    "        # increase the correct prediction count for that label\n",
    "            class_correct[label] += 1\n",
    "\n",
    "    total_accuracy = sum(class_correct)/sum(class_total)\n",
    "    healthy_accuracy = class_correct[0]/class_total[0]\n",
    "    bleeding_accuracy = class_correct[1]/class_total[1]\n",
    "\n",
    "    total_accuracies.append(total_accuracy)\n",
    "    healthy_accuracies.append(healthy_accuracy)\n",
    "    bleeding_accuracies.append(bleeding_accuracy)\n",
    "\n",
    "    if total_accuracy > best_accuracy:\n",
    "        best_accuracy = total_accuracy\n",
    "        best_parameter_combination = par_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673951157Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(len(total_accuracies)), total_accuracies, color='blue', label='Total accuracies for every parameter combination')\n",
    "plt.scatter(range(len(healthy_accuracies)), healthy_accuracies, color='green', label='Healthy accuracies for every parameter combination')\n",
    "plt.scatter(range(len(bleeding_accuracies)), bleeding_accuracies, color='red', label='Bleeding accuracies for every parameter combination')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(decision_function_path, \"accuracies.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameters (get the final accuracy score for function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.673996787Z"
    }
   },
   "outputs": [],
   "source": [
    "# class_correct counts how many correct predictions for that label [corrects_for_label_0, corrects_for_label_1]\n",
    "# class_total counts how many predictions are there for that label [predictions_for_label_0, predictions_for_label_1]\n",
    "class_correct, class_total = [0,0], [0,0]\n",
    "\n",
    "for image, label in tqdm(test_dataloader):\n",
    "    decision = decision_function(image, *best_parameter_combination)\n",
    "    \n",
    "    class_total[label] += 1\n",
    "    if decision == label:\n",
    "    # increase the correct prediction count for that label\n",
    "        class_correct[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.674081397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total: accuracy for whole dataset\n",
    "print(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\")\n",
    "print(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\")\n",
    "print(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\")\n",
    "\n",
    "with open(os.path.join(decision_function_path, \"accuracies.txt\"), 'w') as txt:\n",
    "    txt.write(f\"Total accuracy: {sum(class_correct)/sum(class_total)} on threshold: {THRESHOLD}\\n\")\n",
    "    txt.write(f\"Healthy detection: {class_correct[0]}/{class_total[0]} | accuracy: {class_correct[0]/class_total[0]}\\n\")\n",
    "    txt.write(f\"Bleeding detection: {class_correct[1]}/{class_total[1]} | accuracy: {class_correct[1]/class_total[1]}\\n\")\n",
    "    txt.write(f\"Parameters: {' '.join([str(p) for p in best_parameter_combination])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T15:52:40.674121627Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
